{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in JSON into dataframe\n",
    "df = pd.read_json('StreamingHistory.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows\n",
    "half_rows = df['artistName'].count() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns besides artistNames\n",
    "df = df.drop(columns=['trackName', 'endTime', 'msPlayed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 2 dfs\n",
    "df1, df2 = np.split(df, [int(half_rows)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            artistName   freq\n",
      "0                                Flume  822.0\n",
      "1                         Janis Joplin  779.0\n",
      "2                             Jai Wolf  677.0\n",
      "3                                 GRiZ  663.0\n",
      "4    Big Brother & The Holding Company  455.0\n",
      "..                                 ...    ...\n",
      "381             A Boogie Wit da Hoodie    5.0\n",
      "382                               Cozz    5.0\n",
      "383                               Tyga    5.0\n",
      "384                            6ix9ine    5.0\n",
      "385                           Galantis    5.0\n",
      "\n",
      "[386 rows x 2 columns]\n",
      "----------------------\n",
      "          artistName   freq\n",
      "0         Kanye West  619.0\n",
      "1    Johannes Brahms  508.0\n",
      "2              Flume  493.0\n",
      "3    Vampire Weekend  484.0\n",
      "4           Big Wild  445.0\n",
      "..               ...    ...\n",
      "307    Chrome Sparks    5.0\n",
      "308       Miike Snow    5.0\n",
      "309       Boz Scaggs    5.0\n",
      "310   Electric Guest    5.0\n",
      "311        Sure Sure    5.0\n",
      "\n",
      "[312 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# generate 2 dataframes with unique artists and their frequencies\n",
    "df1_unique_freq = df1['artistName'].value_counts(normalize=True).rename_axis('artistName').reset_index(name='freq')\n",
    "df2_unique_freq = df2['artistName'].value_counts(normalize=True).rename_axis('artistName').reset_index(name='freq')\n",
    "\n",
    "\n",
    "df1_unique_freq['freq'] = pd.Series.round(df1_unique_freq['freq'] * 10000)\n",
    "df2_unique_freq['freq'] = pd.Series.round(df2_unique_freq['freq'] * 10000)\n",
    "\n",
    "\n",
    "print(df1_unique_freq)\n",
    "print('----------------------')\n",
    "print(df2_unique_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ndarray of all unique artists from both dfs\n",
    "full_unique = pd.Series.append(df1_unique_freq['artistName'], df2_unique_freq['artistName']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            artistName    freq_x  \\\n",
      "0                                Flume  0.082245   \n",
      "1                         Janis Joplin  0.077891   \n",
      "2                             Jai Wolf  0.067731   \n",
      "3                                 GRiZ  0.066280   \n",
      "4    Big Brother & The Holding Company  0.045477   \n",
      "..                                 ...       ...   \n",
      "531                         Miike Snow  0.000000   \n",
      "532               Ludwig van Beethoven  0.000000   \n",
      "533                      Booty&theKidd  0.000000   \n",
      "534                              Arlie  0.000000   \n",
      "535                    The Mary Nixons  0.000000   \n",
      "\n",
      "                             artisName                    artistName_full  \\\n",
      "0                                Flume                              Flume   \n",
      "1                         Janis Joplin                       Janis Joplin   \n",
      "2                             Jai Wolf                           Jai Wolf   \n",
      "3                                 GRiZ                               GRiZ   \n",
      "4    Big Brother & The Holding Company  Big Brother & The Holding Company   \n",
      "..                                 ...                                ...   \n",
      "531                                  0                                  0   \n",
      "532                                  0                                  0   \n",
      "533                                  0                                  0   \n",
      "534                                  0                                  0   \n",
      "535                                  0                                  0   \n",
      "\n",
      "       freq_y  \n",
      "0    0.049347  \n",
      "1    0.002903  \n",
      "2    0.011611  \n",
      "3    0.018384  \n",
      "4    0.000000  \n",
      "..        ...  \n",
      "531  0.000484  \n",
      "532  0.000484  \n",
      "533  0.000484  \n",
      "534  0.000484  \n",
      "535  0.000484  \n",
      "\n",
      "[536 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# # create dataframe with combined unique artists and frequencies with NaN values filled with 0\n",
    "test = pd.merge(df1_unique_freq, df2_unique_freq, on=\"artistName\", how=\"outer\").fillna(0)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId  artistId   freq\n",
      "0         0         0  822.0\n",
      "1         0         1  779.0\n",
      "2         0         2  677.0\n",
      "3         0         3  663.0\n",
      "4         0         4  455.0\n",
      "..      ...       ...    ...\n",
      "531       0       531    NaN\n",
      "532       0       532    NaN\n",
      "533       0       533    NaN\n",
      "534       0       534    NaN\n",
      "535       0       535    NaN\n",
      "\n",
      "[536 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Construct final dataset\n",
    "df_x = pd.DataFrame.from_dict({ 'userId' : [0 for i in range(test['artistName'].size)], 'artistId' : [i for i in range(test['artistName'].size)], 'freq' : test['freq_x']})\n",
    "df_y = pd.DataFrame.from_dict({ 'userId' : [1 for i in range(test['artistName'].size)], 'artistId' : [i for i in range(test['artistName'].size)], 'freq' : test['freq_y']})\n",
    "dataset = pd.DataFrame.append(df_x, df_y)\n",
    "\n",
    "print(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId  artistId   freq\n",
      "0         0         0  822.0\n",
      "1         0         1  779.0\n",
      "2         0         2  677.0\n",
      "3         0         3  663.0\n",
      "4         0         4  455.0\n",
      "..      ...       ...    ...\n",
      "531       1       531    5.0\n",
      "532       1       532    5.0\n",
      "533       1       533    5.0\n",
      "534       1       534    5.0\n",
      "535       1       535    5.0\n",
      "\n",
      "[698 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_no_zeros = dataset[dataset['freq'].notna()]\n",
    "dataset_zeros = dataset[dataset['freq'].isna()]\n",
    "\n",
    "print(dataset_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       object\n",
      "artistId     object\n",
      "freq        float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermallalieu/.local/share/virtualenvs/music_recommend-63Qr5cfw/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/christophermallalieu/.local/share/virtualenvs/music_recommend-63Qr5cfw/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# to string\n",
    "\n",
    "dataset_no_zeros['userId'] = dataset_no_zeros['userId'].astype(str)\n",
    "dataset_no_zeros['artistId'] = dataset_no_zeros['artistId'].astype(str)\n",
    "\n",
    "print(dataset_no_zeros.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data into suprise dataset\n",
    "reader = Reader()\n",
    "\n",
    "data_no_zeros = Dataset.load_from_df(dataset_no_zeros[['userId', 'artistId', 'freq']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.trainset.Trainset object at 0x11d8445d0>\n"
     ]
    }
   ],
   "source": [
    "# split dataset into train and test\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# trainset, testset = train_test_split(data_no_zeros, test_size=0.01)\n",
    "\n",
    "trainset = data_no_zeros.build_full_trainset()\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x11d85a790>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit SVD model\n",
    "from surprise import SVD, accuracy\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model accuracy use root mean squared error\n",
    "from surprise import accuracy\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zeros = Dataset.load_from_df(dataset_zeros[['userId', 'artistId', 'freq']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.dataset.DatasetAutoFolds'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data_zeros))\n",
    "\n",
    "trainset, testset = train_test_split(data_zeros, test_size=.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 385, nan), (1, 202, nan), (1, 306, nan), (1, 368, nan), (0, 485, nan), (0, 418, nan), (1, 292, nan), (0, 405, nan), (0, 466, nan), (1, 350, nan), (1, 263, nan), (1, 148, nan), (1, 163, nan), (1, 375, nan), (0, 491, nan), (0, 416, nan), (1, 114, nan), (1, 358, nan), (1, 199, nan), (1, 60, nan), (1, 92, nan), (0, 394, nan), (0, 528, nan), (0, 497, nan), (1, 204, nan), (1, 152, nan), (0, 500, nan), (0, 435, nan), (1, 195, nan), (0, 413, nan), (1, 223, nan), (0, 434, nan), (1, 371, nan), (0, 511, nan), (1, 133, nan), (0, 457, nan), (1, 331, nan), (0, 401, nan), (1, 365, nan), (0, 467, nan), (0, 403, nan), (0, 468, nan), (1, 327, nan), (0, 483, nan), (1, 75, nan), (1, 94, nan), (0, 425, nan), (1, 344, nan), (0, 471, nan), (1, 211, nan), (0, 447, nan), (0, 431, nan), (1, 46, nan), (0, 488, nan), (0, 438, nan), (0, 470, nan), (0, 525, nan), (1, 151, nan), (1, 128, nan), (0, 480, nan), (1, 180, nan), (1, 194, nan), (1, 138, nan), (0, 392, nan), (1, 91, nan), (1, 239, nan), (0, 486, nan), (1, 315, nan), (1, 106, nan), (1, 119, nan), (0, 408, nan), (0, 512, nan), (1, 323, nan), (0, 529, nan), (1, 183, nan), (0, 423, nan), (1, 233, nan), (1, 184, nan), (1, 20, nan), (1, 229, nan), (1, 126, nan), (0, 527, nan), (1, 297, nan), (0, 517, nan), (1, 339, nan), (1, 140, nan), (0, 532, nan), (0, 492, nan), (1, 334, nan), (1, 217, nan), (0, 414, nan), (0, 474, nan), (1, 308, nan), (0, 484, nan), (1, 276, nan), (1, 256, nan), (1, 186, nan), (0, 404, nan), (1, 380, nan), (1, 120, nan), (0, 481, nan), (1, 85, nan), (1, 54, nan), (0, 442, nan), (0, 495, nan), (0, 411, nan), (1, 360, nan), (1, 280, nan), (0, 496, nan), (0, 509, nan), (1, 157, nan), (1, 384, nan), (1, 196, nan), (0, 464, nan), (1, 38, nan), (1, 185, nan), (1, 135, nan), (1, 225, nan), (1, 105, nan), (0, 436, nan), (0, 440, nan), (1, 254, nan), (0, 490, nan), (1, 158, nan), (1, 236, nan), (1, 329, nan), (1, 192, nan), (1, 291, nan), (1, 214, nan), (0, 493, nan), (1, 266, nan), (1, 90, nan), (0, 432, nan), (0, 520, nan), (0, 402, nan), (0, 508, nan), (0, 429, nan), (1, 244, nan), (1, 337, nan), (1, 218, nan), (0, 424, nan), (1, 347, nan), (1, 325, nan), (0, 426, nan), (1, 231, nan), (1, 335, nan), (1, 364, nan), (0, 530, nan), (1, 13, nan), (1, 351, nan), (1, 310, nan), (0, 430, nan), (1, 363, nan), (1, 279, nan), (0, 515, nan), (1, 247, nan), (1, 58, nan), (1, 178, nan), (1, 345, nan), (1, 309, nan), (1, 210, nan), (0, 454, nan), (1, 271, nan), (1, 193, nan), (0, 476, nan), (0, 396, nan), (1, 4, nan), (1, 269, nan), (1, 139, nan), (1, 288, nan), (0, 450, nan), (0, 410, nan), (0, 533, nan), (0, 531, nan), (1, 71, nan), (0, 449, nan), (0, 516, nan), (1, 264, nan), (1, 182, nan), (1, 220, nan), (1, 294, nan), (1, 354, nan), (0, 463, nan), (1, 88, nan), (1, 251, nan), (1, 361, nan), (1, 159, nan), (0, 422, nan), (1, 376, nan), (1, 209, nan), (1, 107, nan), (1, 307, nan), (0, 443, nan), (1, 238, nan), (0, 462, nan), (0, 506, nan), (0, 513, nan), (1, 109, nan), (1, 359, nan), (0, 510, nan), (0, 386, nan), (0, 439, nan), (0, 478, nan), (1, 322, nan), (1, 248, nan), (1, 226, nan), (1, 227, nan), (0, 400, nan), (0, 498, nan), (1, 353, nan), (0, 459, nan), (0, 514, nan), (0, 519, nan), (0, 518, nan), (1, 172, nan), (1, 311, nan), (1, 316, nan), (1, 267, nan), (1, 197, nan), (1, 121, nan), (1, 296, nan), (1, 113, nan), (1, 207, nan), (0, 398, nan), (0, 501, nan), (0, 391, nan), (1, 167, nan), (1, 80, nan), (1, 189, nan), (1, 282, nan), (1, 42, nan), (0, 451, nan), (1, 289, nan), (0, 472, nan), (0, 428, nan), (1, 377, nan), (0, 507, nan), (1, 341, nan), (0, 387, nan), (1, 213, nan), (1, 319, nan), (1, 191, nan), (0, 417, nan), (0, 420, nan), (1, 187, nan), (1, 257, nan), (1, 261, nan), (1, 81, nan), (1, 250, nan), (0, 437, nan), (1, 198, nan), (1, 287, nan), (1, 243, nan), (1, 237, nan), (1, 300, nan), (0, 524, nan), (0, 445, nan), (0, 395, nan), (0, 482, nan), (1, 65, nan), (1, 118, nan), (1, 265, nan), (0, 465, nan), (0, 406, nan), (0, 535, nan), (1, 55, nan), (0, 446, nan), (1, 104, nan), (1, 154, nan), (0, 388, nan), (0, 409, nan), (1, 215, nan), (0, 389, nan), (0, 390, nan), (1, 132, nan), (0, 407, nan), (0, 489, nan), (0, 421, nan), (0, 526, nan), (1, 162, nan), (0, 460, nan), (1, 295, nan), (1, 41, nan), (0, 494, nan), (1, 373, nan), (1, 93, nan), (1, 136, nan), (1, 53, nan), (1, 260, nan), (0, 504, nan), (0, 475, nan), (0, 455, nan), (0, 477, nan), (0, 534, nan), (1, 330, nan), (1, 381, nan), (1, 129, nan), (1, 79, nan), (0, 502, nan), (0, 419, nan), (1, 177, nan), (0, 397, nan), (0, 393, nan), (1, 228, nan), (0, 412, nan), (0, 473, nan), (1, 304, nan), (1, 268, nan), (1, 134, nan), (1, 112, nan), (1, 181, nan), (1, 212, nan), (1, 255, nan), (0, 499, nan), (1, 241, nan), (1, 15, nan), (1, 87, nan), (1, 343, nan), (1, 245, nan), (1, 116, nan), (0, 444, nan), (0, 448, nan), (1, 165, nan), (1, 240, nan), (0, 458, nan), (1, 366, nan), (1, 332, nan), (1, 222, nan), (0, 487, nan), (0, 503, nan), (0, 399, nan), (1, 146, nan), (1, 84, nan), (1, 175, nan), (0, 441, nan), (1, 122, nan), (1, 201, nan), (1, 150, nan), (1, 277, nan), (1, 62, nan), (1, 11, nan), (1, 108, nan), (1, 259, nan), (1, 326, nan), (1, 336, nan), (1, 131, nan), (0, 452, nan), (1, 230, nan), (0, 505, nan), (0, 522, nan), (0, 427, nan), (1, 206, nan), (1, 99, nan), (1, 293, nan), (0, 523, nan), (1, 314, nan), (1, 174, nan), (0, 456, nan), (0, 461, nan), (0, 433, nan), (0, 479, nan), (1, 188, nan), (0, 415, nan), (0, 453, nan), (1, 5, nan), (1, 305, nan), (1, 313, nan), (0, 469, nan), (0, 521, nan), (1, 66, nan), (1, 249, nan), (1, 125, nan), (1, 115, nan), (1, 275, nan)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "uids = testset[:]\n",
    "print(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid=1, iid=195, r_ui=0.0004837929366231253, est=1, details={'was_impossible': False})]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
